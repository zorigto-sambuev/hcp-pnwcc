{"version":3,"file":"streaming.js","sources":["../../../../src/utils/anthropic-ai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { setTokenUsageAttributes } from '../ai/utils';\nimport type { AnthropicAiStreamingEvent } from './types';\n\n/**\n * State object used to accumulate information from a stream of Anthropic AI events.\n */\n\ninterface StreamingState {\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId: string;\n  /** The model name. */\n  responseModel: string;\n  /** Number of prompt/input tokens used. */\n  promptTokens: number | undefined;\n  /** Number of completion/output tokens used. */\n  completionTokens: number | undefined;\n  /** Number of cache creation input tokens used. */\n  cacheCreationInputTokens: number | undefined;\n  /** Number of cache read input tokens used. */\n  cacheReadInputTokens: number | undefined;\n}\n\n/**\n * Checks if an event is an error event\n * @param event - The event to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n * @returns Whether an error occurred\n */\n\nfunction isErrorEvent(\n  event: AnthropicAiStreamingEvent,\n  state: StreamingState,\n  recordOutputs: boolean,\n  span: Span,\n): boolean {\n  if ('type' in event && typeof event.type === 'string') {\n    // If the event is an error, set the span status and capture the error\n    // These error events are not rejected by the API by default, but are sent as metadata of the response\n    if (event.type === 'error') {\n      const message = event.error?.message ?? 'internal_error';\n      span.setStatus({ code: SPAN_STATUS_ERROR, message });\n      captureException(new Error(`anthropic_stream_error: ${message}`), {\n        mechanism: {\n          handled: false,\n          type: 'auto.ai.anthropic',\n          data: {\n            function: 'anthropic_stream_error',\n          },\n        },\n        data: {\n          function: 'anthropic_stream_error',\n        },\n      });\n      return true;\n    }\n\n    if (recordOutputs && event.type === 'content_block_delta') {\n      const text = event.delta?.text;\n      if (text) state.responseTexts.push(text);\n    }\n  }\n  return false;\n}\n\n/**\n * Processes the message metadata of an event\n * @param event - The event to process\n * @param state - The state of the streaming process\n */\n\nfunction handleMessageMetadata(event: AnthropicAiStreamingEvent, state: StreamingState): void {\n  // The token counts shown in the usage field of the message_delta event are cumulative.\n  // @see https://docs.anthropic.com/en/docs/build-with-claude/streaming#event-types\n  if (event.type === 'message_delta' && event.usage) {\n    if ('output_tokens' in event.usage && typeof event.usage.output_tokens === 'number') {\n      state.completionTokens = event.usage.output_tokens;\n    }\n  }\n\n  if (event.message) {\n    const message = event.message;\n\n    if (message.id) state.responseId = message.id;\n    if (message.model) state.responseModel = message.model;\n    if (message.stop_reason) state.finishReasons.push(message.stop_reason);\n\n    if (message.usage) {\n      if (typeof message.usage.input_tokens === 'number') state.promptTokens = message.usage.input_tokens;\n      if (typeof message.usage.cache_creation_input_tokens === 'number')\n        state.cacheCreationInputTokens = message.usage.cache_creation_input_tokens;\n      if (typeof message.usage.cache_read_input_tokens === 'number')\n        state.cacheReadInputTokens = message.usage.cache_read_input_tokens;\n    }\n  }\n}\n\n/**\n * Processes an event\n * @param event - The event to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n */\n\nfunction processEvent(\n  event: AnthropicAiStreamingEvent,\n  state: StreamingState,\n  recordOutputs: boolean,\n  span: Span,\n): void {\n  if (!(event && typeof event === 'object')) {\n    return;\n  }\n\n  const isError = isErrorEvent(event, state, recordOutputs, span);\n  if (isError) return;\n\n  handleMessageMetadata(event, state);\n}\n\n/**\n * Instruments an async iterable stream of Anthropic events, updates the span with\n * streaming attributes and (optionally) the aggregated output text, and yields\n * each event from the input stream unchanged.\n */\nexport async function* instrumentStream(\n  stream: AsyncIterable<AnthropicAiStreamingEvent>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<AnthropicAiStreamingEvent, void, unknown> {\n  const state: StreamingState = {\n    responseTexts: [],\n    finishReasons: [],\n    responseId: '',\n    responseModel: '',\n    promptTokens: undefined,\n    completionTokens: undefined,\n    cacheCreationInputTokens: undefined,\n    cacheReadInputTokens: undefined,\n  };\n\n  try {\n    for await (const event of stream) {\n      processEvent(event, state, recordOutputs, span);\n      yield event;\n    }\n  } finally {\n    // Set common response attributes if available\n    if (state.responseId) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_ID_ATTRIBUTE]: state.responseId,\n      });\n    }\n    if (state.responseModel) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: state.responseModel,\n      });\n    }\n\n    setTokenUsageAttributes(\n      span,\n      state.promptTokens,\n      state.completionTokens,\n      state.cacheCreationInputTokens,\n      state.cacheReadInputTokens,\n    );\n\n    span.setAttributes({\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    });\n\n    if (state.finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(state.finishReasons),\n      });\n    }\n\n    if (recordOutputs && state.responseTexts.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: state.responseTexts.join(''),\n      });\n    }\n\n    span.end();\n  }\n}\n"],"names":[],"mappings":";;;;;AAaA;AACA;AACA;;AAqBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAS,YAAY;AACrB,EAAE,KAAK;AACP,EAAE,KAAK;AACP,EAAE,aAAa;AACf,EAAE,IAAI;AACN,EAAW;AACX,EAAE,IAAI,MAAA,IAAU,KAAA,IAAS,OAAO,KAAK,CAAC,IAAA,KAAS,QAAQ,EAAE;AACzD;AACA;AACA,IAAI,IAAI,KAAK,CAAC,IAAA,KAAS,OAAO,EAAE;AAChC,MAAM,MAAM,UAAU,KAAK,CAAC,KAAK,EAAE,OAAA,IAAW,gBAAgB;AAC9D,MAAM,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,iBAAiB,EAAE,OAAA,EAAS,CAAC;AAC1D,MAAM,gBAAgB,CAAC,IAAI,KAAK,CAAC,CAAC,wBAAwB,EAAE,OAAO,CAAC,CAAA,CAAA,EAAA;AACA,QAAA,SAAA,EAAA;AACA,UAAA,OAAA,EAAA,KAAA;AACA,UAAA,IAAA,EAAA,mBAAA;AACA,UAAA,IAAA,EAAA;AACA,YAAA,QAAA,EAAA,wBAAA;AACA,WAAA;AACA,SAAA;AACA,QAAA,IAAA,EAAA;AACA,UAAA,QAAA,EAAA,wBAAA;AACA,SAAA;AACA,OAAA,CAAA;AACA,MAAA,OAAA,IAAA;AACA;;AAEA,IAAA,IAAA,aAAA,IAAA,KAAA,CAAA,IAAA,KAAA,qBAAA,EAAA;AACA,MAAA,MAAA,IAAA,GAAA,KAAA,CAAA,KAAA,EAAA,IAAA;AACA,MAAA,IAAA,IAAA,EAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,IAAA,CAAA;AACA;AACA;AACA,EAAA,OAAA,KAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,SAAA,qBAAA,CAAA,KAAA,EAAA,KAAA,EAAA;AACA;AACA;AACA,EAAA,IAAA,KAAA,CAAA,IAAA,KAAA,eAAA,IAAA,KAAA,CAAA,KAAA,EAAA;AACA,IAAA,IAAA,eAAA,IAAA,KAAA,CAAA,KAAA,IAAA,OAAA,KAAA,CAAA,KAAA,CAAA,aAAA,KAAA,QAAA,EAAA;AACA,MAAA,KAAA,CAAA,gBAAA,GAAA,KAAA,CAAA,KAAA,CAAA,aAAA;AACA;AACA;;AAEA,EAAA,IAAA,KAAA,CAAA,OAAA,EAAA;AACA,IAAA,MAAA,OAAA,GAAA,KAAA,CAAA,OAAA;;AAEA,IAAA,IAAA,OAAA,CAAA,EAAA,EAAA,KAAA,CAAA,UAAA,GAAA,OAAA,CAAA,EAAA;AACA,IAAA,IAAA,OAAA,CAAA,KAAA,EAAA,KAAA,CAAA,aAAA,GAAA,OAAA,CAAA,KAAA;AACA,IAAA,IAAA,OAAA,CAAA,WAAA,EAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,OAAA,CAAA,WAAA,CAAA;;AAEA,IAAA,IAAA,OAAA,CAAA,KAAA,EAAA;AACA,MAAA,IAAA,OAAA,OAAA,CAAA,KAAA,CAAA,YAAA,KAAA,QAAA,EAAA,KAAA,CAAA,YAAA,GAAA,OAAA,CAAA,KAAA,CAAA,YAAA;AACA,MAAA,IAAA,OAAA,OAAA,CAAA,KAAA,CAAA,2BAAA,KAAA,QAAA;AACA,QAAA,KAAA,CAAA,wBAAA,GAAA,OAAA,CAAA,KAAA,CAAA,2BAAA;AACA,MAAA,IAAA,OAAA,OAAA,CAAA,KAAA,CAAA,uBAAA,KAAA,QAAA;AACA,QAAA,KAAA,CAAA,oBAAA,GAAA,OAAA,CAAA,KAAA,CAAA,uBAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAA,YAAA;AACA,EAAA,KAAA;AACA,EAAA,KAAA;AACA,EAAA,aAAA;AACA,EAAA,IAAA;AACA,EAAA;AACA,EAAA,IAAA,EAAA,KAAA,IAAA,OAAA,KAAA,KAAA,QAAA,CAAA,EAAA;AACA,IAAA;AACA;;AAEA,EAAA,MAAA,OAAA,GAAA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,CAAA;AACA,EAAA,IAAA,OAAA,EAAA;;AAEA,EAAA,qBAAA,CAAA,KAAA,EAAA,KAAA,CAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gBAAA,gBAAA;AACA,EAAA,MAAA;AACA,EAAA,IAAA;AACA,EAAA,aAAA;AACA,EAAA;AACA,EAAA,MAAA,KAAA,GAAA;AACA,IAAA,aAAA,EAAA,EAAA;AACA,IAAA,aAAA,EAAA,EAAA;AACA,IAAA,UAAA,EAAA,EAAA;AACA,IAAA,aAAA,EAAA,EAAA;AACA,IAAA,YAAA,EAAA,SAAA;AACA,IAAA,gBAAA,EAAA,SAAA;AACA,IAAA,wBAAA,EAAA,SAAA;AACA,IAAA,oBAAA,EAAA,SAAA;AACA,GAAA;;AAEA,EAAA,IAAA;AACA,IAAA,WAAA,MAAA,KAAA,IAAA,MAAA,EAAA;AACA,MAAA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,CAAA;AACA,MAAA,MAAA,KAAA;AACA;AACA,GAAA,SAAA;AACA;AACA,IAAA,IAAA,KAAA,CAAA,UAAA,EAAA;AACA,MAAA,IAAA,CAAA,aAAA,CAAA;AACA,QAAA,CAAA,4BAAA,GAAA,KAAA,CAAA,UAAA;AACA,OAAA,CAAA;AACA;AACA,IAAA,IAAA,KAAA,CAAA,aAAA,EAAA;AACA,MAAA,IAAA,CAAA,aAAA,CAAA;AACA,QAAA,CAAA,+BAAA,GAAA,KAAA,CAAA,aAAA;AACA,OAAA,CAAA;AACA;;AAEA,IAAA,uBAAA;AACA,MAAA,IAAA;AACA,MAAA,KAAA,CAAA,YAAA;AACA,MAAA,KAAA,CAAA,gBAAA;AACA,MAAA,KAAA,CAAA,wBAAA;AACA,MAAA,KAAA,CAAA,oBAAA;AACA,KAAA;;AAEA,IAAA,IAAA,CAAA,aAAA,CAAA;AACA,MAAA,CAAA,mCAAA,GAAA,IAAA;AACA,KAAA,CAAA;;AAEA,IAAA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,GAAA,CAAA,EAAA;AACA,MAAA,IAAA,CAAA,aAAA,CAAA;AACA,QAAA,CAAA,wCAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,aAAA,CAAA;AACA,OAAA,CAAA;AACA;;AAEA,IAAA,IAAA,aAAA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,GAAA,CAAA,EAAA;AACA,MAAA,IAAA,CAAA,aAAA,CAAA;AACA,QAAA,CAAA,8BAAA,GAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,EAAA,CAAA;AACA,OAAA,CAAA;AACA;;AAEA,IAAA,IAAA,CAAA,GAAA,EAAA;AACA;AACA;;;;"}